{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMK8iiMmDW1qUMwNuuttIf1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Polineska/SpeechRecognition/blob/main/vosk_analysisGolos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-WC97U7y1Us"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "!sudo apt update && sudo apt install ffmpeg\n",
        "!pip install jiwer -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install vosk"
      ],
      "metadata": {
        "id": "mAaau6LPznlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.executable\n",
        "import os\n",
        "import warnings\n",
        "import jiwer\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "tOV0a0pJy7Su"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#bond005/sberdevices_golos_10h_crowd_noised_2db #для зашумленных аудиоданных\n",
        "DATASET_ID = \"bond005/sberdevices_golos_10h_crowd\" #для незашумленных\n",
        "SAMPLES = 9900\n",
        "\n",
        "test_dataset = load_dataset(DATASET_ID, split=f\"test[:{SAMPLES}]\")\n",
        "\n"
      ],
      "metadata": {
        "id": "OaawnNxezQc5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from vosk import Model, KaldiRecognizer\n",
        "import wave\n",
        "import json\n",
        "import vosk\n",
        "import jiwer\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import re"
      ],
      "metadata": {
        "id": "RbaBOuS_0NSf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def speech_file_to_array_fn(batch):\n",
        "    audio_file = batch[\"audio\"].get(\"path\")\n",
        "    if audio_file is not None:\n",
        "        try:\n",
        "            speech_array, sampling_rate = librosa.load(audio_file, sr=16000)\n",
        "            speech_array = speech_array.astype(np.int16)\n",
        "            batch[\"speech\"] = speech_array\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading file {audio_file}: {e}\")\n",
        "    return batch\n",
        "\n",
        "# Предобработка датасета\n",
        "removed_columns = set(test_dataset.column_names)\n",
        "removed_columns -= {'transcription', 'speech'}\n",
        "removed_columns = sorted(list(removed_columns))\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "    test_dataset = test_dataset.map(\n",
        "        speech_file_to_array_fn,\n",
        "        remove_columns=removed_columns\n",
        "    )\n",
        "\n",
        "def infer_vosk(samples): # Функция для распознавания речи с помощью Vosk\n",
        "    transcripts = []\n",
        "    model = Model(lang='ru')\n",
        "    for i, sample in enumerate(samples):\n",
        "        if \"speech\" in sample:\n",
        "            audio = sample[\"speech\"]\n",
        "            rec = KaldiRecognizer(model, 16000)\n",
        "            rec.SetMaxAlternatives(10)\n",
        "            rec.SetPartialWords(True)\n",
        "\n",
        "            # Распознавание речи\n",
        "            rec.AcceptWaveform(audio.tobytes())\n",
        "            result = rec.FinalResult()\n",
        "\n",
        "            # Получение текста распознавания\n",
        "            if isinstance(result, dict):\n",
        "                alternatives = result.get_alternatives()\n",
        "                if alternatives:\n",
        "                    transcript_text = alternatives[0].get('text', '')\n",
        "                else:\n",
        "                  transcript_text = ''\n",
        "                  transcripts.append(transcript_text)\n",
        "\n",
        "            return transcripts\n",
        "hypotheses = infer_vosk(test_dataset)\n",
        "references = test_dataset[\"transcription\"]"
      ],
      "metadata": {
        "id": "qk0HEBKt0Hvd"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def infer_vosk(samples):\n",
        "    transcripts = []\n",
        "    model = Model(lang='ru')\n",
        "    for sample in samples:\n",
        "        if \"speech\" in sample:\n",
        "            audio = sample[\"speech\"]\n",
        "            rec = KaldiRecognizer(model, 16000)\n",
        "            rec.SetMaxAlternatives(10)\n",
        "            rec.SetPartialWords(True)\n",
        "\n",
        "            # Распознавание речи\n",
        "            rec.AcceptWaveform(audio.tobytes())\n",
        "            result = rec.FinalResult()\n",
        "\n",
        "            # Получение текста распознавания\n",
        "            if result:\n",
        "                if isinstance(result, dict):\n",
        "                    alternatives = result.get('alternatives', [])\n",
        "                else:\n",
        "                    alternatives = result.alternatives\n",
        "                if alternatives:\n",
        "                    transcript_text = alternatives[0]['text']\n",
        "                    transcripts.append(transcript_text)\n",
        "    return transcripts\n",
        "hypotheses = infer_vosk(test_dataset)\n",
        "references = test_dataset[\"transcription\"]"
      ],
      "metadata": {
        "id": "CkniDlW-8gp5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(dict(hypothesis_small=hypotheses, reference_small=references))"
      ],
      "metadata": {
        "id": "ShMwskYb5rtf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        text = str(text)\n",
        "\n",
        "    # Удаление знаков пунктуации и преобразование в нижний регистр\n",
        "    text = re.sub(r'[^\\w\\s]', '', text).lower()\n",
        "\n",
        "    # Удаление множественных пробелов\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "refs = test_dataset[\"transcription\"]\n",
        "normalized_refs = [normalize_text(ref) for ref in refs]\n",
        "normalized_hyps = [normalize_text(hyp) if hyp else '' for hyp in hypotheses]\n",
        "max_length = max(len(normalized_refs), len(normalized_hyps))\n",
        "normalized_refs += ['' for _ in range(max_length - len(normalized_refs))]\n",
        "normalized_hyps += ['' for _ in range(max_length - len(normalized_hyps))]\n",
        "wer_score = jiwer.wer(normalized_refs, normalized_hyps)\n",
        "print(f\"\\nWER crowd_noised: {wer_score * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QeL8syd5iGj",
        "outputId": "cdc8dcb0-c16f-4f4c-8449-88d0f6ae5b3a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "WER crowd_noised: 87.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wer_score = jiwer.wer(normalized_refs, normalized_hyps)\n",
        "print(f\"\\nWER crowd: {wer_score * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "k3tmScEq42cZ",
        "outputId": "b6cb3256-dd54-4b26-fc63-ec7ad2083b9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "WER crowd: 19.42%\n"
          ]
        }
      ]
    }
  ]
}